{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=gpu\"\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "%matplotlib inline\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import scipy.ndimage as nd\n",
    "from lasagnekit.misc.draw_net import draw_to_notebook, draw_to_file\n",
    "from lasagnekit.misc.plot_weights import grid_plot\n",
    "from lasagnekit.misc.dream import build_dreamer\n",
    "from lasagnekit.easy import LightweightModel, BatchOptimizer\n",
    "\n",
    "from lasagne import layers, updates\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from lasagnekit.easy import get_stat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from lasagne.layers import InputLayer, DenseLayer, NonlinearityLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "from lasagne.layers.cuda_convnet.\n",
    "\n",
    "\n",
    "import PIL\n",
    "\n",
    "from cStringIO import StringIO\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display\n",
    "\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "\n",
    "def preprocess(mv, img):\n",
    "    return np.float32(np.rollaxis(img, 2)[::-1]) - mv\n",
    "def deprocess(mv, img):\n",
    "    return np.dstack((img + mv)[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose which model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "requires a GPU to work",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-92dc40944382>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mvgg19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgooglenet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"googlenet\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"vgg\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/grid_mnt/vol__vol_U__u/gridcl/mehdicherti/work/code/zoo/lasagne/vgg19.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#from lasagne.layers import Pool2DLayer as PoolLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrmm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv2DMMLayer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mConvLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaxPool2DLayer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mPoolLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/grid_mnt/vol__vol_U__u/gridcl/mehdicherti/build/Lasagne/lasagne/layers/corrmm.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"requires a GPU to work\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: requires a GPU to work"
     ]
    }
   ],
   "source": [
    "import vgg19, googlenet\n",
    "\n",
    "model_name = \"googlenet\"\n",
    "\n",
    "if model_name == \"vgg\":\n",
    "    build_model = vgg19.build_model\n",
    "    model_filename = \"vgg19.pkl\"\n",
    "elif model_name == \"googlenet\":\n",
    "    build_model = googlenet.build_model\n",
    "    model_filename = \"blvc_googlenet.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = build_model()\n",
    "model_data = pickle.load(open(model_filename))\n",
    "values = model_data['param values']\n",
    "layers.set_all_param_values(net['prob'], values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some information from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = net\n",
    "classes = np.array(model_data[\"synset words\"])\n",
    "\n",
    "# mean value of the colors from which the model was trained on\n",
    "# it is important because the model was trained on the images\n",
    "# with subsracting the mean\n",
    "if \"mean value\" in model_data:\n",
    "    mean_value = (model_data[\"mean value\"])\n",
    "else:\n",
    "    mean_value = np.array([104.0, 116.0, 122.0])\n",
    "\n",
    "mean_value = mean_value[:, np.newaxis, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_to_file(layers.get_all_layers(model['prob']), \"{0}.svg\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVG(\"{0}.svg\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace the links by the images you want to use\n",
    "!wget http://www.dph.am/sky1024px.jpg --output-document=sample.png\n",
    "!wget http://i.ytimg.com/vi/s9dbAfjlrks/maxresdefault.jpg --output-document=sample2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the loaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_natural = np.float32(PIL.Image.open('sample.png'))\n",
    "showarray(img_natural)\n",
    "img_natural = np.float32(PIL.Image.open('sample2.png'))\n",
    "showarray(img_natural)\n",
    "img_natural = np.float32(PIL.Image.open('sample3.png'))\n",
    "showarray(img_natural)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Blending Dream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are using these images\n",
    "original_images = [\n",
    "    np.float32(PIL.Image.open('sample.png')),\n",
    "#    np.float32(PIL.Image.open('sample2.png')),\n",
    " #   np.float32(PIL.Image.open('sample3.png')),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show the name of the layers of the model, choose a set of layers\n",
    "# and use them below\n",
    "for name in model.keys():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the optimization procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose the layers you want to use for blending\n",
    "end_layers = [\n",
    "    \"inception_4d/5x5_reduce\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup theano stuff\n",
    "t_generated_image = T.tensor4()\n",
    "t_input_images = T.tensor4()\n",
    "\n",
    "input_activations = [] # the input (original images) activations of the chosen layers\n",
    "generated_activations = [] # the generated activations of the chosen layers\n",
    "\n",
    "for layer_name in end_layers:\n",
    "    o_input_images = layers.get_output(model[layer_name], t_input_images)\n",
    "    input_activations.append(o_input_images)\n",
    "    \n",
    "    o_generated_image = layers.get_output(model[layer_name], t_generated_image)[0]\n",
    "    generated_activations.append(o_generated_image)\n",
    "\n",
    "t_activations = []\n",
    "for a in generated_activations:\n",
    "    t_activations.append(a.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify the kind of loss we want to minimize, \n",
    "# here squared error between desired  and generated\n",
    "# activations is used\n",
    "L = 0\n",
    "for t_generated, t_desired in zip(generated_activations, t_activations):\n",
    "    L += 0.5 * ((t_generated - t_desired) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate theano functions to perform the optimization\n",
    "get_activations = theano.function([t_input_images], input_activations)\n",
    "get_gradients = theano.function([t_generated_image] + t_activations, \n",
    "                                 theano.grad(L, t_generated_image) )\n",
    "get_loss = theano.function([t_generated_image] + t_activations, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare (initialize) the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h, w = 200, 300 # we rescale to this size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocess the original images\n",
    "images = [preprocess(mean_value, image).astype(np.float32) for image in original_images]\n",
    "images = [resize(image, (3, h, w), preserve_range=True).astype(np.float32) for image in images]\n",
    "input_images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate randomly the initial image and preprocess it\n",
    "generated_image = np.random.uniform(0, 255, size=original_images[0].shape)\n",
    "generated_image = preprocess(mean_value, generated_image).astype(np.float32)\n",
    "generated_image = resize(generated_image, (3, h, w), preserve_range=True).astype(np.float32)\n",
    "generated_image = generated_image[np.newaxis, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for lbfgs\n",
    "def eval_loss(x0):\n",
    "    x0 = (x0.reshape((1, 3, h, w))).astype(np.float32)\n",
    "    return get_loss(x0, *layers_desired_activations).astype(np.float64)\n",
    "\n",
    "def eval_grad(x0):\n",
    "    x0 = (x0.reshape((1, 3, h, w))).astype(np.float32)\n",
    "    g = get_gradients(generated_image_, *layers_desired_activations)\n",
    "    return g.flatten().astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Optimize !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.001 # learning rate of gradient descent\n",
    "nb_iterations = 100\n",
    "generated_image_ = generated_image.copy()\n",
    "loss_per_epoch = []\n",
    "use_lbfgs = False # Use LBFGS to optimize better (if False, use gradient descent)\n",
    "\n",
    "# get the activations of the original images for each layer\n",
    "layers_activations = get_activations(input_images)\n",
    "    \n",
    "for i in range(nb_iterations):\n",
    "    \n",
    "    # Prepare the desired activations for the generated images\n",
    "    # by combining the activations of the original images\n",
    "    layers_desired_activations = []\n",
    "    for layer_activations in layers_activations:\n",
    "        # Blending operation@\n",
    "        \n",
    "        # replace HERE by whatever blending operation you want\n",
    "        # layer_activations is a 4D tensor in case the layer\n",
    "        # is convolutional where : scipy.fill\n",
    "        # dim 1 = the image index\n",
    "        # dim 2 = the index of the feature map\n",
    "        # dim 3 = y\n",
    "        # dim 4 = x\n",
    "        # In case the layer is fully connected, layer_activations\n",
    "        # is a matrix where:\n",
    "        # dim 1 = the image index\n",
    "        # dim 2 = the feature index\n",
    "        \n",
    "        # Here we just use the mean of the features of the original images\n",
    "        \n",
    "        #layer_desired_activations = np.sqrt((layer_activations**2).mean(axis=0))\n",
    "        #layer_desired_activations = np.zeros(layer_activations.shape[1:], dtype=np.float32)\n",
    "        \n",
    "        #nb = layer_desired_activations.shape[0]\n",
    "        \n",
    "        #layer_desired_activations[0:nb/2] = layer_activations[0, 0:nb/2, :, :]\n",
    "        #layer_desired_activations[nb/2:] = layer_activations[1, nb/2:, :, :]\n",
    "        layer_desired_activations = layer_activations.mean(axis=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        layers_desired_activations.append(layer_desired_activations)\n",
    "    \n",
    "    if use_lbfgs is True:\n",
    "      \n",
    "        x0, _, _ = fmin_l_bfgs_b(eval_loss, \n",
    "                                 generated_image_.flatten(), \n",
    "                                 fprime=eval_grad, maxfun=50)\n",
    "        generated_image_[:] = (x0.reshape(generated_image_.shape).astype(np.float32))\n",
    "    else:\n",
    "        # just use gradient descent if use_lbfgs is False\n",
    "        \n",
    "        # get gradient w.r.t the input\n",
    "        g = get_gradients(generated_image_, *layers_desired_activations)\n",
    "        # do one step of gradient descent\n",
    "        \n",
    "        y = np.random.randint(0, h - 400)\n",
    "        x = np.random.randint(0, w - 400)\n",
    "        \n",
    "        generated_image_ = (generated_image_ - alpha * g)\n",
    "        \n",
    "        \n",
    "\n",
    "    l = get_loss(generated_image_, *layers_desired_activations)\n",
    "    loss_per_epoch.append(l)\n",
    "    if i % 1==0:\n",
    "        print(l)\n",
    "    if i % 10==0:\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        out = deprocess(mean_value, images[0])\n",
    "        out = np.uint8(np.clip(out, 0, 255))\n",
    "        plt.title(\"original\")\n",
    "        plt.axis('off')\n",
    "        plt.imshow(out)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        out = deprocess(mean_value, generated_image_[0])\n",
    "        out = np.uint8(np.clip(out, 0, 255))\n",
    "        plt.title(\"generated\")\n",
    "        plt.imshow(out)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = deprocess(mean_value, generated_image_[0])\n",
    "showarray(out)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
