{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=gpu0\"\n",
    "os.environ[\"CPATH\"] = \"\"\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "from lasagnekit.misc.draw_net import draw_to_notebook, draw_to_file\n",
    "from lasagnekit.misc.plot_weights import grid_plot\n",
    "from lasagnekit.misc.dream import build_dreamer\n",
    "from lasagnekit.easy import LightweightModel, BatchOptimizer\n",
    "from lasagnekit.generative.capsule import Capsule\n",
    "from lasagnekit.easy import BatchIterator, get_batch_slice\n",
    "\n",
    "\n",
    "from lasagnekit.datasets.mnist import MNIST\n",
    "from lasagnekit.datasets.fonts import Fonts\n",
    "from lasagnekit.datasets.rescaled import Rescaled\n",
    "from lasagnekit.datasets.dtd import DTD\n",
    "from lasagnekit.datasets.cached import Cached\n",
    "\n",
    "from lasagne import layers, updates\n",
    "from IPython.display import SVG\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "\n",
    "srng = RandomStreams(seed=234)\n",
    "\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from lasagnekit.easy import get_stat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lasagne.layers import InputLayer, DenseLayer, NonlinearityLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.nonlinearities import softmax, rectify\n",
    "from lasagne.init import GlorotUniform, Constant\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from utils import TransposedConv2DLayer, Conv2DDenseLayer\n",
    "\n",
    "from caffezoo.googlenet import GoogleNet\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "googlenet = GoogleNet(input_size=(28, 28))\n",
    "googlenet._load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "rng = RandomStreams(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, h = 28, 28 # Desired resolution, not necessarely the same than real_w and real_h, \n",
    "              # if necessary the images will be resize to fit w and h)\n",
    "nb_colors = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = DTD(examples_filter=np.arange(200))\n",
    "data.load()\n",
    "data_rescaled = Cached(Rescaled(data, size=(w, h)))\n",
    "data_rescaled.load()\n",
    "X = data_rescaled.X\n",
    "y = data_rescaled.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], nb_colors, w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in (googlenet._net.keys()):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_size = 5\n",
    "latent_size = 500\n",
    "num_filters = 64\n",
    "\n",
    "l_latent = googlenet._net[\"pool1/norm1\"]\n",
    "\n",
    "\n",
    "\n",
    "l_decoder1 = layers.Conv2DLayer(l_latent, \n",
    "                                filter_size=(3, 3),\n",
    "                                pad='full',\n",
    "                                num_filters=32)\n",
    "l_decoder2 = layers.Conv2DLayer(l_decoder1, \n",
    "                                filter_size=(5, 5),\n",
    "                                pad='full',\n",
    "                                num_filters=32)\n",
    "l_decoder3 = layers.Conv2DLayer(l_decoder2, \n",
    "                                filter_size=(7, 7),\n",
    "                                pad='full',\n",
    "                                num_filters=32)\n",
    "l_decoder3 = layers.Conv2DLayer(l_decoder2, \n",
    "                                filter_size=(9, 9),\n",
    "                                pad='full',\n",
    "                                num_filters=32)\n",
    "print(layers.get_output_shape(l_latent, (100, 3, 28, 28)))\n",
    "#l_decoder_out = l_unconv\n",
    "#x_to_z = LightweightModel([l_in], [l_latent])\n",
    "#z_to_x = LightweightModel([l_latent], [l_decoder_out])\n",
    "#model = Model()\n",
    "#model.x_to_z = x_to_z\n",
    "#model.z_to_x = z_to_x\n",
    "#print(l_conv.W.get_value().shape)\n",
    "#print(l_unconv.W.get_value().shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
