{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=gpu0\"\n",
    "os.environ[\"CPATH\"] = \"\"\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "from lasagnekit.misc.draw_net import draw_to_notebook, draw_to_file\n",
    "from lasagnekit.misc.plot_weights import grid_plot\n",
    "from lasagnekit.misc.dream import build_dreamer\n",
    "from lasagnekit.easy import LightweightModel, BatchOptimizer\n",
    "from lasagnekit.generative.capsule import Capsule\n",
    "from lasagnekit.easy import BatchIterator, get_batch_slice\n",
    "\n",
    "\n",
    "from lasagnekit.datasets.mnist import MNIST\n",
    "from lasagnekit.datasets.fonts import Fonts\n",
    "from lasagnekit.datasets.rescaled import Rescaled\n",
    "from lasagnekit.datasets.dtd import DTD\n",
    "from lasagnekit.datasets.cached import Cached\n",
    "from lasagnekit.datasets.faces import Faces\n",
    "from lasagnekit.datasets.cifar100 import Cifar100\n",
    "\n",
    "from lasagnekit.misc.plot_weights import grid_plot\n",
    "from lasagne import layers, updates\n",
    "from IPython.display import SVG\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "\n",
    "srng = RandomStreams(seed=234)\n",
    "\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from lasagnekit.easy import get_stat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lasagne.layers import InputLayer, DenseLayer, NonlinearityLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.nonlinearities import softmax, rectify\n",
    "from lasagne.init import GlorotUniform, Constant\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from utils import TransposedConv2DLayer, Conv2DDenseLayer, TransposedDenseLayer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "rng = RandomStreams(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose between mnist and fonts\n",
    "dataset = \"cifar\"\n",
    "w, h = 28, 28 # Desired resolution, not necessarely the same than real_w and real_h, \n",
    "              # if necessary the images will be resize to fit w and h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if dataset == \"mnist\":\n",
    "    data = MNIST()\n",
    "elif dataset == \"fonts\":\n",
    "    data = Fonts(kind=\"all_64\", \n",
    "                 labels_kind=\"letters\")\n",
    "elif dataset == \"textures\":\n",
    "    data = DTD(examples_filter=np.arange(2000))\n",
    "    data.load()\n",
    "elif dataset == \"cifar\":\n",
    "    data = Cifar100()\n",
    "    \n",
    "data_rescaled = Cached(Rescaled(data, size=(w, h)))\n",
    "data_rescaled.load()\n",
    "X = data_rescaled.X\n",
    "if hasattr(data_rescaled, \"y\"):\n",
    "    y = data_rescaled.y\n",
    "else:\n",
    "    y = np.ones((X.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(data_rescaled.img_dim) == 3:\n",
    "    nb_colors = data_rescaled.img_dim[0]\n",
    "else:\n",
    "    nb_colors = 1 # gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.shape, y.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], nb_colors, w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "train, test = train_test_split(range(X.shape[0]), test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_images = X\n",
    "input_images_ = input_images.transpose((0, 2, 3, 1))\n",
    "\n",
    "if input_images_.shape[-1] == 1:\n",
    "    input_images_ = input_images_[:, :, :, 0]\n",
    "    \n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "n = 5\n",
    "gridw, gridh = n, n\n",
    "k = 1\n",
    "ind = 0\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        plt.subplot(gridw, gridh, k)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(input_images_[ind], cmap=\"gray\")\n",
    "        k += 1\n",
    "        ind += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        self.extra_params = []\n",
    "    def get_all_params(self, **kwargs):\n",
    "        return (list(set(self.x_to_z.get_all_params(**kwargs) + \n",
    "                        self.z_to_x.get_all_params(**kwargs)))+self.extra_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_type = \"fully_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne import init\n",
    "if model_type == \"fully_connected\":\n",
    "    ## fully connected\n",
    "    latent_size = 1000\n",
    "    \n",
    "    #thresh = theano.shared(np.random.uniform(-0.001, 0.001, size=(latent_size,)).astype(np.float32))\n",
    "\n",
    "    l_in = layers.InputLayer((None, nb_colors, w, h), name=\"input\")\n",
    "    l_latent = layers.DenseLayer(l_in, \n",
    "                                 num_units=latent_size,\n",
    "                                 name=\"latent\",\n",
    "                                 #W=init.Uniform(range=0.001),\n",
    "                                 #W=init.Uniform(range=0.27),\n",
    "                                 #nonlinearity=T.nnet.sigmoid,\n",
    "                                 nonlinearity=lambda x:(  T.abs_(x) > 0.2)*x,\n",
    "                                 #nonlinearity=lambda x:rectify(x+thresh)* (x/(x+thresh)),\n",
    "                                 #b=Constant(0.),\n",
    "                                 b=None\n",
    "                                 )\n",
    "    l_decoder_out = TransposedDenseLayer(l_latent, num_units=nb_colors*w*h,\n",
    "                                         W=l_latent.W,\n",
    "                                         #W=init.Uniform(range=0.2734344),\n",
    "                                         b=Constant(0.),\n",
    "                                         nonlinearity=None)\n",
    "    l_decoder_out = layers.ReshapeLayer(l_decoder_out, ([0], nb_colors, w, h))\n",
    "    x_to_z = LightweightModel([l_in], [l_latent])\n",
    "    z_to_x = LightweightModel([l_latent], [l_decoder_out])\n",
    "    model = Model()\n",
    "    model.x_to_z = x_to_z\n",
    "    model.z_to_x = z_to_x\n",
    "    #model.extra_params.append(thresh)\n",
    "    \n",
    "    \n",
    "    def show_filters(all_layers, shuffled=True, nbrows=10, nbcols=10):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        V = all_layers[1].W.get_value() #> all_layers[1].b.get_value()[:, None, None, None]\n",
    "        min_val = V.min(axis=1)[:, None]\n",
    "        max_val = V.max(axis=1)[:, None]\n",
    "        V = (V - min_val) / (max_val - min_val)\n",
    "        V = V.T.reshape((-1, nb_colors, w, h))\n",
    "        V = V.transpose((0, 2, 3, 1)) \n",
    "        V_ = V[:, :, :, 0] if V.shape[-1] == 1 else V\n",
    "        s = np.arange(V_.shape[0])\n",
    "        np.random.shuffle(s)\n",
    "        grid_plot(V_[s, :, :], imshow_options={\"cmap\": \"gray\"}, nbrows=nbrows, nbcols=nbcols)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_filters(all_layers, shuffled=True, nbrows=10, nbcols=10):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    V = all_layers[1].W.get_value() #> all_layers[1].b.get_value()[:, None, None, None]\n",
    "    min_val = V.min(axis=1)[:, None]\n",
    "    max_val = V.max(axis=1)[:, None]\n",
    "    V = (V - min_val) / (max_val - min_val)\n",
    "    V = V.T.reshape((-1, nb_colors, w, h))\n",
    "    V = V.transpose((0, 2, 3, 1)) \n",
    "    V_ = V[:, :, :, 0] if V.shape[-1] == 1 else V\n",
    "    s = np.arange(V_.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    grid_plot(V_[s, :, :], imshow_options={\"cmap\": \"gray\"}, nbrows=nbrows, nbcols=nbcols)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model_type == \"convnet\":\n",
    "    filter_size = 5\n",
    "    latent_size = 50\n",
    "    num_filters = 64\n",
    "    \n",
    "    l_in = layers.InputLayer((None, nb_colors, None, None), name=\"input\")    \n",
    "    l_conv = layers.Conv2DLayer(l_in, num_filters=num_filters, \n",
    "                                filter_size=(filter_size, filter_size),\n",
    "                                name=\"conv1\")\n",
    "    l_conv_2 = layers.Conv2DLayer(l_conv, num_filters=num_filters, \n",
    "                                  filter_size=(filter_size, filter_size),\n",
    "                                  name=\"conv2\")\n",
    "    sw = w - 2 * filter_size + 2\n",
    "    l_latent = Conv2DDenseLayer(l_conv_2, \n",
    "                                num_units=latent_size,\n",
    "                                name=\"latent\",\n",
    "                                nonlinearity=None,# linear    \n",
    "                                filter_size=(sw, sw))\n",
    "                                \n",
    "    l_un_latent = layers.Conv2DLayer(l_latent, \n",
    "                                     num_filters=num_filters,\n",
    "                                     filter_size=(sw, sw), \n",
    "                                     pad='full',\n",
    "                                     name=\"un_latent\")\n",
    "    \n",
    "    \n",
    "    l_unconv_2 = layers.Conv2DLayer(l_un_latent, num_filters=num_filters, \n",
    "                                   filter_size=(filter_size, filter_size),\n",
    "                                   pad=\"full\",\n",
    "                                   name=\"unconv_2\")\n",
    "    l_unconv = layers.Conv2DLayer(l_unconv_2, num_filters=nb_colors, \n",
    "                                  filter_size=(filter_size, filter_size),\n",
    "                                  pad=\"full\",\n",
    "                                  name=\"unconv_1\")\n",
    "\n",
    "    l_decoder_out = l_unconv\n",
    "    \n",
    "    \"\"\"\n",
    "    l_in = layers.InputLayer((None, nb_colors, None, None), name=\"input\")    \n",
    "    l_conv = layers.Conv2DLayer(l_in, num_filters=num_filters, filter_size=(filter_size, filter_size), name=\"conv1\")\n",
    "    \n",
    "    l_pool = layers.Pool2DLayer(l_conv, pool_size=(2, 2), name=\"pool1\")\n",
    "    #l_pool = l_conv\n",
    "    \n",
    "    # sw = (w - filter_size + 1)\n",
    "    sw = (w - filter_size + 1) / 2\n",
    "\n",
    "    l_latent = Conv2DDenseLayer(l_pool, \n",
    "                                num_units=latent_size,\n",
    "                                name=\"latent\",\n",
    "                                nonlinearity=None,# linear    \n",
    "                                filter_size=(sw, sw))\n",
    "                                \n",
    "    l_un_latent = layers.Conv2DLayer(l_latent, \n",
    "                                     num_filters=num_filters,\n",
    "                                     filter_size=(sw, sw), \n",
    "                                     pad='full',\n",
    "                                     name=\"un_latent\")\n",
    "    \n",
    "    l_unpool = layers.Upscale2DLayer(l_un_latent, 2, name=\"unpool1\")\n",
    "    #l_unpool = l_un_latent\n",
    "    l_unconv = layers.Conv2DLayer(l_unpool, num_filters=nb_colors, \n",
    "                                  filter_size=(filter_size, filter_size),\n",
    "                                  #W=l_conv.W,\n",
    "                                  name=\"unconv1\",\n",
    "                                  pad='full',\n",
    "                                  nonlinearity=None)\n",
    "    l_decoder_out = l_unconv\n",
    "    \"\"\"\n",
    "    print(layers.get_output_shape(l_decoder_out, (100, 3, 28, 28)))\n",
    "    x_to_z = LightweightModel([l_in], [l_latent])\n",
    "    z_to_x = LightweightModel([l_latent], [l_decoder_out])\n",
    "    model = Model()\n",
    "    model.x_to_z = x_to_z\n",
    "    model.z_to_x = z_to_x\n",
    "    \n",
    "    \n",
    "    def show_filters(all_layers):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        V = all_layers[1].W.get_value() #> all_layers[1].b.get_value()[:, None, None, None]\n",
    "        V = V.transpose((0, 2, 3, 1)) \n",
    "        min_val = V.min(axis=(1, 2, 3))[:, None, None, None]\n",
    "        max_val = V.max(axis=(1, 2, 3))[:, None, None, None]\n",
    "        V = (V - min_val) / (max_val - min_val)\n",
    "        V_ = V[:, :, :, 0] if V.shape[-1] == 1 else V\n",
    "        grid_plot(V_, imshow_options={\"cmap\": \"gray\"})\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers_by_name = OrderedDict()\n",
    "\n",
    "\n",
    "all_layers = (\n",
    "    layers.get_all_layers(model.x_to_z.output_layers[0]) +\n",
    "    layers.get_all_layers(model.z_to_x.output_layers[0])\n",
    ")\n",
    "\n",
    "for l in all_layers:\n",
    "    if l.name is not None:\n",
    "        layers_by_name[l.name] = l\n",
    "print(layers_by_name.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the capsule object\n",
    "\n",
    "The Capsule object combines all the components:\n",
    "\n",
    "    - The model\n",
    "    - The training algorithm\n",
    "    - The loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_variables = OrderedDict()\n",
    "input_variables[\"input_image\"] = dict(tensor_type=T.tensor4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_function(model, tensors, noise=False):\n",
    "    input_image = tensors[\"input_image\"]    \n",
    "    input_image_old = input_image\n",
    "    #noisify\n",
    "    if noise is True:\n",
    "        print(noise)\n",
    "        #input_image = input_image * (rng.uniform(size=input_image.shape) <= 0.7)\n",
    "        input_image = input_image + rng.normal(std=0.01, size=input_image.shape)\n",
    "    output = get_output(model, input_image)    \n",
    "    \n",
    "    recons = ((input_image_old - output) ** 2)\n",
    "    #recons = (input_image_old * T.nnet.softplus(-output) + (1 - input_image_old) * T.nnet.softplus(output))\n",
    "    recons = recons.sum(axis=(1, 2, 3))\n",
    "    return recons.mean()\n",
    "\n",
    "def get_latent(model, input_image):\n",
    "    z, = model.x_to_z.get_output(input_image)\n",
    "    return z\n",
    "\n",
    "def get_output(model, input_image):\n",
    "    z = get_latent(model, input_image)\n",
    "    o, = model.z_to_x.get_output(z)\n",
    "    return o\n",
    "\n",
    "def get_output_from_latent(model, latent):\n",
    "    o, = model.z_to_x.get_output(latent)\n",
    "    return o\n",
    "\n",
    "def get_loss(model, input_image):\n",
    "    return loss_function(model, {\"input_image\": input_image}, noise=True)\n",
    "\n",
    "def get_loss_deterministic(model, input_image):\n",
    "    return loss_function(model, {\"input_image\": input_image}, noise=False)\n",
    "\n",
    "functions = dict(\n",
    "    get_output=dict(\n",
    "        get_output=get_output,\n",
    "        params=[\"input_image\"]\n",
    "    ),   \n",
    "    get_latent=dict(\n",
    "        get_output=get_latent,\n",
    "        params=[\"input_image\"]\n",
    "    ),\n",
    "    get_loss=dict(\n",
    "        get_output=get_loss,\n",
    "        params=[\"input_image\"]\n",
    "    ),\n",
    "    get_loss_deterministic=dict(\n",
    "        get_output=get_loss_deterministic,\n",
    "        params=[\"input_image\"]\n",
    "    )\n",
    "  \n",
    ")\n",
    "\n",
    "class MyBatchOptimizer(BatchOptimizer):\n",
    "    # called for each epoch during training\n",
    "    def iter_update(self, epoch, nb_batches, iter_update_batch):\n",
    "        status = super(MyBatchOptimizer, self).iter_update(epoch, nb_batches, iter_update_batch)\n",
    "        nb = 200\n",
    "        status[\"train_loss\"] = self.model.get_loss_deterministic(X[train][0:nb])\n",
    "        status[\"test_loss\"] = self.model.get_loss_deterministic(X[test][0:nb])\n",
    "\n",
    "        if (status[\"epoch\"] % 10) == 0:\n",
    "            show_filters(all_layers)\n",
    "        return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_optimizer = MyBatchOptimizer(\n",
    "    max_nb_epochs=100,\n",
    "    verbose=1,\n",
    "    batch_size=100,\n",
    "    optimization_procedure=(updates.adam, {\"learning_rate\": 0.001})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capsule = Capsule(\n",
    "    input_variables, \n",
    "    model,\n",
    "    loss_function,\n",
    "    functions=functions,\n",
    "    batch_optimizer=batch_optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "capsule.fit(input_image=X[train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(model.extra_params[0].get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_images = X\n",
    "input_images = input_images[np.random.randint(0, input_images.shape[0], size=150)]\n",
    "output_images = capsule.get_output(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_images_ = input_images.transpose((0, 2, 3, 1))\n",
    "\n",
    "def a(x):\n",
    "    return x\n",
    "    return 1./(1.+np.exp(-x))\n",
    "output_images_ = a(output_images.transpose((0, 2, 3, 1)))\n",
    "\n",
    "if input_images_.shape[-1] == 1:\n",
    "    input_images_ = input_images_[:, :, :, 0]\n",
    "    \n",
    "if output_images_.shape[-1] == 1:\n",
    "    output_images_ = output_images_[:, :, :, 0]\n",
    "    \n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "n = 5\n",
    "gridw, gridh = n*2, n*2\n",
    "k = 1\n",
    "ind = 0\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        plt.subplot(gridw, gridh, k)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(input_images_[ind], cmap=\"gray\")\n",
    "        k += 1\n",
    "        plt.subplot(gridw, gridh, k)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(output_images_[ind], cmap=\"gray\")\n",
    "        k += 1\n",
    "        ind += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!wget http://i.imgur.com/2HVJF0t.gif --output-document=image.gif\n",
    "#!wget http://www.mescoloriages.com/coloriages/animaux/cheval/cheval%201/images/chevaux_1_015.gif --output-document=image.gif\n",
    "\n",
    "#!wget http://i.imgur.com/iqZBF6A.jpg --output-document=image.jpg # im1\n",
    "#!wget http://jmg.j.m.pic.centerblog.net/it3ahbzg.jpg --output-document=image.jpg #im2\n",
    "#!wget http://jmg.j.m.pic.centerblog.net/c4j703bp.jpg --output-document=image.jpg #im3\n",
    "#!wget http://www.freelargeimages.com/wp-content/uploads/2014/12/Landscape_01.jpg --output-document=image.jpg # im4\n",
    "\n",
    "#!wget http://www.mescoloriages.com/coloriages/animaux/cheval/chevaux%205/images/chevaux_5_008.gif --output-document=image.gif\n",
    "#!wget http://www2.mes-coloriages-preferes.biz/colorino/Images/Large/Animaux-Cheval-3756.png --output-document=image.gif\n",
    "#!wget https://sustainability.uic.edu/files/2013/11/Tree.jpg --output-document=image.jpg --no-check-certificate\n",
    "#!wget http://www.vbctulsa.com/wordpress/wp-content/uploads/2015/02/wrackthetree.jpg --output-document=image.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.transform import resize\n",
    "image = (imread(\"image.jpg\"))\n",
    "print(image.shape)\n",
    "image = resize(image, (256, 256))\n",
    "#image = image[:, :, 0] # RGB?\n",
    "#print(image)\n",
    "image = 1 - image\n",
    "if len(image.shape) == 2:\n",
    "    image = image[:, :, None] * np.ones((1, 1, nb_colors))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "im = image[:, :, 0] if nb_colors == 1 else image\n",
    "orig_im = im.copy()\n",
    "plt.imshow(1-im, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_ = (image.transpose((2, 0, 1)).astype(np.float32))[None, :, :, :].copy()\n",
    "print(image_.shape)\n",
    "for i in range(3):\n",
    "    image_ = capsule.get_output(image_)\n",
    "image__ = image_.transpose((0, 2, 3, 1))\n",
    "\n",
    "im = image__[0, :, :, 0] if nb_colors == 1 else image__[0]\n",
    "\n",
    "alpha=0.03\n",
    "im = (im - im.min()) / (im.max() - im.min())\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.imshow( (1-im), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_filters(all_layers, nbrows=30, nbcols=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
